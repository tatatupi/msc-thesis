%-------------------------------------------------------------------------------
\chapter{Numerical Results}\label{cap5} 
\vspace{-1cm} \vspace{1cm}

%\begin{flushright}
%\begin{minipage}{0.7\linewidth}
%\emph{``O homem é como uma função, cujo numerador é o que ele é e
%cujo denominador é o que ele pensa dele mesmo. Quanto maior o
%denominador, menor a fração.''}
%\end{minipage}
%\end{flushright}
%
%\begin{flushright}
%{L. N. Tolstói}
%\end{flushright}

%\section{Introdução}

In this chapter, we present simulation results of state estimation for two different sampled-data systems: an arbitrary linear system with two underdamped modes and a nonholomonic unicycle position system. Both systems are described in state-space representations. We also present three simulation scenarios designed to enable the evaluation of the effects of aperiodic sampling in state estimation when we neglect information about the time-stamps. 

Since simulations are carried out in digital computers, it is impossible to simulate the continuous-time variables of the sampled-data systems. Therefore, we try to reproduce the actual values of the states in a continuous manner, by choosing very small time steps $\delta t_\textrm{sim}$ to simulate the nominal system model. The continuous random time intervals $h_k$, $k\in \mathbb{N}$ are generated by the exponential probability distribution function from Matlab and resulting time instants $t_k$ are then approximated to the nearest discrete time instant, among all available samples.

\section{Design of Simulation Scenarios}\label{sec:scenarios}

To evaluate performance and consistency effects of the aperiodic sampling in state estimation, we study three scenarios: variation of noise level in signals, or SNR; variation of average measurement sampling rate $\lambda$; and variation of the relation between $\lambda$ and the regular estimation sampling rate $1/T$, that is $\alpha$. 

In the first scenario we intend to study how performance is affected by the presence of different noise levels in the signals. It is expected that the higher the noise, the closer will be performance of both algorithms. That is because the additional noise tuned by not considering time-stamp information will be small in comparison to larger data noise level. The second scenario assesses how the average sampling rate of measurements is related to degradation in performance when time-stamp is not considered in state estimation. Therefore, the speed of system dynamics in comparison to the sampling rate is investigated. In the last simulation scenario we study the behavior of the effects when the regular estimation time interval distances itself from the average time interval of the observations. Additional errors due to measurement time instants approximation are expected to influence performance results.

Since estimation is performed in the presence of random quantities, then several runs of simulations need to be carried out, so that confidence intervals can be constructed towards more consistent conclusions. We calculate average values from all runs with the corresponding $95\%$ confidence intervals for accuracy index $RMSE$, given by (\ref{eq:rmse}), and consistency tests $NEES$, given by (\ref{eq:nees}) and (\ref{eq:nees_h0}), and $NIS$, given by (\ref{eq:nis}) and (\ref{eq:nis_h0}). In Table~\ref{tab:symbols} we review some of the concepts and symbols that are extensively used in this chapter


\begin{table}[!ht]
	\small
	\centering
	\setlength{\tabcolsep}{12pt}
	\caption[Review of concepts and symbols used in simulation]{Review of concepts and symbols used in simulation}
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{S M L}	
		\toprule
		Concept / Symbol	& Definition  &  Description \\ 
		\midrule
		$\lambda$ (Section~\ref{sec:problem_form})		& $h_k \sim \mathcal{E} (\lambda)$ & Average sampling rate of observations, in Hertz, determining random time intervals $h_k$   \\ 
		$T$	(Section~\ref{sec:problem_form})				& $t_i \triangleq iT$ & Regular estimation time interval, given in seconds \\ 
		$\alpha$ (Section~\ref{sec:problem_form})			& $\frac{1}{\lambda} \triangleq \alpha T$ & Relation between regular estimation time interval $T$ and average irregular time interval of observations $1/\lambda$   \\
		SNR (\ref{eq:snr_db}) 				& $SNR_{\textrm{dB}} \triangleq 10 \log_{10}\frac{P_{\textrm{signal}}}{P_{\textrm{noise}}}$ & Ratio between signal power $P_{\textrm{signal}}$ and noise power $P_{\textrm{noise}}$ in decibel, related to the level of data uncertainty \\
		NEES (\ref{eq:nees})			& $NEES \triangleq  \tilde{x}^T(P^{xx})^{-1}\tilde{x}$ & Value tested to be chi-squared distributed, in case of estimate error consistency \\
		NIS (\ref{eq:nis})					& $NIS \triangleq  \eta^T(P^{yy})^{-1}\eta$ & Value tested to be chi-squared distributed, in case of innovation consistency  \\ 
		
		\bottomrule		
	\end{tabular}
	\label{tab:symbols}
\end{table}

\normalsize
\section{Linear System}

Our first system of choice is a fourth-order LTI system, since its results are more controllable and difference equations calculations have an exact solution. Thus results comparison and assessment are expected to be more clear and comprehensive. Additionally, we choose the combination of two independent modes, each of second order and with distinct dynamics, so the effects can be evaluated separately.

\subsection{System Description}

The linear system chosen for simulation is the serial combination of two second order underdamped modes, with different band pass behaviors. Figure~\ref{fig:bode} shows the bode diagrams of both systems separately. One of the modes, henceforth termed as low-pass ($\textrm{lp}$) system, has a time constant $\tau_{\textrm{lp}} = 1$ s, a natural frequency $\omega_{n,\textrm{lp}} = 10$ Hz and a damping constant of $\zeta_{\textrm{lp}}=0.1$. The frequency response is then given by

\begin{equation}\label{eq:low-pass}
G_{\textrm{lp}}(s) = \frac{100}{s^2 + 2s + 100}.
\end{equation}

\noindent
The second mode is a high-pass ($\textrm{hp}$) system, with a lower time constant $\tau_{\textrm{hp}} = 0.01$ s, a higher natural frequency $\omega_{n,\textrm{hp}} = 1000$ Hz, and same damping constant of $\zeta_{\textrm{hp}}=0.1$, with two zeros, one at the origin and another one at $0.001$. The high-pass frequency response is given by:

\begin{equation}\label{eq:high-pass}
G_{\textrm{hp}}(s) = \frac{s^2-0.001s}{s^2 + 200s + 10^6}.\\
\end{equation}
\noindent

%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.6\textwidth]{Imagens/stepResponse.eps}
%	\caption[entrada]{Step response of both low-pass and high-pass modes.}
%	\label{fig:stepResponse}
%\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{Imagens/bode.eps}
	\caption[Bode diagram of both modes]{Bode diagram of both modes. Blue represent the low-pass system (\ref{eq:low-pass}) and red the high-pass system (\ref{eq:high-pass}).}
	\label{fig:bode}
\end{figure}

%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.6\textwidth]{Imagens/bodeS.eps}
%	\caption[entrada]{Bode diagram of the resulting fourth order system.}
%	\label{fig:bodeS}
%\end{figure}


The resulting fourth order system is described as a state space representation, in a modal canonical form given by:

\begin{align}
\dot{x}(t) & = Ax(t) + Bu(t) \label{eq:sys_beg}\\
y(t) & = Cx(t) + Du(t)
\end{align}


\noindent
where $x(t) \in \mathbb{R}^4$ is the state vector, $u(t) \in \mathbb{R}^1$ is the single input vector and $y(t) \in \mathbb{R}^1$ is the single output vector, and

\begin{align}
A & =\begin{bmatrix}
-100 & 994.99 & 0 & 0\\
-994.99 & -100 & 0 & 0\\
0 & 0 & -1 & 9.949\\
0 & 0 & -9.949 & -1
\end{bmatrix}, \label{eq:linear_A}\\
B & =\begin{bmatrix}
-24.6435 \\
-18.8943 \\
-4.1746 \\
-0.2675
\end{bmatrix}, \\
C & =\begin{bmatrix}
24.41 & -21.2522 & -0.1537 & 2.3977 \\
\end{bmatrix}, \\
D & =1. \label{eq:sys_end}
\end{align}

\noindent
Matrix $A$, given by (\ref{eq:linear_A}), indicates two subsystem dynamically decoupled. The upper diagonal block refers to the high-pass system (\ref{eq:high-pass}), whereas the lower diagonal block represents the low-pass system (\ref{eq:low-pass}).

%
%\begin{equation}\label{eq:sistemaLinear}
%\begin{split}
%Z_{de} & := (\partial Z/\partial \delta_e)/m = -61.655 \ m/s^2,\\
%Z_q & := (\partial Z/\partial q)/m = -5.132 \ m/s,\\
%Z_w & := (\partial Z/\partial W)/m = -3.1332 \ s^{-1},\\
%M_{de} & := (\partial M/\partial \delta_e)/I_y = -40.465 \ s^{-2},\\
%M_q & := (\partial M/\partial q)/I_y = -2.6864 \ s^{-1},\\
%M_w & := (\partial M/\partial W)/I_y = -0.04688 \ (s-m)^{-1},\\
%\tau & = 0.1 \ s \\
%U_o & = 306.42 \ m/s
%\end{split}
%\end{equation}

We simulate a pseudo-random binary sequence (PRBS) as input, with 200 samples, as shown in Figure~\ref{fig:prbs}. The PRBS signal is used as input to the low-pass and high-pass systems separately, considering two different time frames, of 2 and 20 seconds. The results of the four linear simulations are shown in Figure~\ref{fig:sys_results}. The 20 seconds simulation for the high-pass system achieve steady state values very quickly, with a dynamics hard to be observed. Thus, we choose the 2 seconds time frame to simulate the fourth order serialized systems, given by (\ref{eq:sys_beg})-(\ref{eq:sys_end}). The result of the linear simulation of the fourth order system is presented in Figure~\ref{fig:4ordersys2s}.


\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{Imagens/prbs.eps}
	\caption[PRBS samples used as input]{200 PRBS samples used as input to simulate system (\ref{eq:sys_beg})-(\ref{eq:sys_end})}
	\label{fig:prbs}
\end{figure}

\begin{figure}[!htb]
 	\centering
 	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/lp2s.eps}} 
 	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/lp20s.eps}}  \\
 	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/hp2s.eps}}
 	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/hp20s.eps}}
 	\caption[Linear simulation results for PRBS input in different time frames]{Linear simulation results of the low-pass and high-pass systems separately. Grey lines represent the PRBS input and colored lines the output. Graphs (a) and (b) with blue outputs represent the results of the low-pass system; and (c) and (d) with red outputs, the results of the high-pass system. Graphs on the left show a time frame of 2 seconds of simulations, whereas the ones on the right are the result of a 20 seconds time frame; considering the same 200 samples of PRBS for all four simulations.} 
 	\label{fig:sys_results}
 \end{figure}


\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{Imagens/4ordersys2s.eps}
	\caption[Output of the fourth order system to the PRBS input signal]{Output of the fourth order system to the PRBS input signal over a 2 seconds time frame.}
	\label{fig:4ordersys2s}
\end{figure}

System discretization is performed using Matlab\texttrademark's built-in function \texttt{c2d} to produce a discrete-time state space representations according to

\begin{align}
x(t_{k+1}) &= A_{\textrm{d}}(t_k) x(t_k) + B_{\textrm{d}} u(t_k) + w(t_k), \\
y(t_k) &= B_{\textrm{d}}x(t)+D_{\textrm{d}}u(t) + v(t_k)
\end{align}

\noindent
where $t_{k+1} = t_k + h_k \in \mathbb{R}$ and $k \in \mathbb{N}$. $\rho(v(t_k)) = \mathcal{N} (0,R)$ and $\rho(w(t_k)) = \mathcal{N} (0,Q)$ are, respectively, the process and observation noise, with zero mean and covariance $R$ and $Q$. When time-stamp is not available, the observation vector is approximated by $\tilde{y}_i \approx y(t_k)$, where $i$ is the index of the next regular estimation time instant, multiple of $T$. When it is available, discretization is performed using variable time intervals.

\subsection{Linear System}

In this section we present one realization of the state estimation simulation for the system defined by (\ref{eq:sys_beg})-(\ref{eq:sys_end}), using the Kalman Filter described in Section~\ref{sec:kalman-filter} and the algorithms modifications explained in Section~\ref{sec:estimation_aperiodic}.  

Simulation parameters are set according to $\lambda = 500 \textrm{ Hz}$, $SNR_{\textrm{obs}} = 30 \textrm{ dB}$, and $SNR_{\textrm{pro}} = 30 \textrm{ dB}$, where subscript $\textrm{obs}$ and $\textrm{obs}$ refer to observation and process, respectively. Time step to simulate nominal system model is set as $\delta t_{\textrm{sim}} = 10^{-6} \textrm{ s}$ and the regular estimation time interval is given by $T = 2\times 10^{-3} \textrm{ s}$. Noise is generated using the \texttt{awgn} function from Matlab\texttrademark. For this realization, it resulted in a measurement noise variance of $R=9.596\times 10^{-4}$ and process noise variance of $Q=9.986\times 10^{-4}$. These exact values were used in the Kalman filter implementation and the estimation results for states $x_1$ and $x_4$ of the algorithms with and without timestamp, in comparison to the true state values are shown in Figures~\ref{fig:StatesWithAndWithoutTimeStamp}.

\begin{figure}[!htb]
	\centering
	\subfigure{\includegraphics[width=0.8\textwidth]{Imagens/StatesWithTimeStamp.eps}} \\
	\subfigure{\includegraphics[width=0.8\textwidth]{Imagens/StatesWithoutTimeStamp.eps}}  
	\caption[Estimated and true states]{States $x_1$ and $x_4$ estimates with time-stamp (\textcolor{red}{- -}), without time-stamp (\textcolor{blue}{- -}) and true values (\textcolor{black}{---}).}
	\label{fig:StatesWithAndWithoutTimeStamp}
\end{figure}

For the high-pass subsystem state $x_1$, it is hard to note a significant difference in the estimation performance. However, for the low-pass system state $x_4$, the degradation is visible for the algorithm that does not acknowledge time instants $t_k$ information in the estimation process, represented by the dashed blue lines.


Figure~\ref{fig:LinearJevolution} presents a data window from 0 to 0.013 seconds of the accuracy index RMSE of state $x_2$, for the algorithms with and without time-stamp. As expected, when first observation arrives at $t_1$, RMSE results distance themselves, in favor of the algorithm that considers time-stamp. For the time period without observations, indexes of both algorithms evolve in a similar way. When measurements start to appear back again, we can notice further degradation in the performance when time-stamps are not considered, like in $t_3$ and $t_4$.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{Imagens/LinearJEvolution.eps}
	\caption[Performance index temporal cut for one realization]{Temporal cut from 0 to 0.013 seconds, for a realization of state $x_2$ RMSE for	 both estimators, with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Vertical dashed lines match the measurement sampling instants $t_k$. Black dots represent the estimation instants.}
	\label{fig:LinearJevolution}
\end{figure}

Finally, for this realization, we also present single-run consistency tests, using the indices NEES and NIS as defined in Section~\ref{sec:metrics} in Figure~\ref{fig:linearConsistency}. In each graph, the acceptance intervals are marked by horizontal lines. The upper plots (a) and (b) represent the NEES and NIS values, respectively, for the algorithm that considers time-stamp in the estimation process. We can see that the estimates are quite consistent, with the values inside the acceptance region most of the time. In fact, the null hypothesis rejection rate, that is the proportion of times the values were out of their acceptance region, was $4\%$ for NEES, and $5,5\%$ for NIS, very close the the $5\%$ expected. When time-stamp information was not available, consistency was heavily degraded, with rejection rates escalating to $61\%$ and $43\%$, respectively. Moreover, NEES and NIS values were so high in some occasions, that the acceptance region is hardly visible in the graphs. In practice, such a consistency degradation means that estimation covariances are highly underestimated.

 \begin{figure}[!htb]
	\centering
	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/chi_e_with.eps}} 
	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/chi_eta_with.eps}}  \\
	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/chi_e_without.eps}}
	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/chi_eta_without.eps}}
	\caption[Consistency tests for linear system]{Consistency tests NEEs and NIS for the linear system state estimation with time-stamps (a) and (b); and without time-stamp (c) and (d). Horizontal lines define the acceptance region upper and lower limits, for a significance level $\alpha=0.05$. In each graph, the null hypothesis $H_0$ rejection rate is also presented.}
	\label{fig:linearConsistency}
\end{figure}

In the next sections we study the scenarios described in Section~\ref{sec:scenarios} for multiple runs. The simulation parameters are defined according to Table~\ref{tab:params_linear}
Only the results of one state per mode are shown, namely $x_1$ and $x_4$, for simplicity sake.. Figure~\ref{fig:linear_sim} encompasses results for all scenarios. Each column contains the performance metrics variation for each scenario. A 100-run Monte Carlo simulation was performed for each of them, and the mean and $95\%$ confidence intervals are presented for the algorithm with time-stamp in red and without time-stamp in blue.

\begin{table}[!ht]
	\centering
	\setlength{\tabcolsep}{12pt}
	\caption[Linear system simulation parameters for SNR variation]{Linear system simulation parameters for SNR variation}
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{c | c | c | c }
		\toprule
		Scenario & SNR (dB)	& $\lambda$ (Hz) & $\alpha$\\
		\midrule
		SNR variation & $[60,\ 50,\ 40,\ 20,\ 10]$	& $500$ & $1$ \\ 
		$\lambda$ variation & $30$		&  $[1000,\ 500,\ 200,\ 100]$ & $1$  \\ 
		$\alpha$ variation & $30$		&  $500$ & $[5,\ 3,\ 2,\ 1]$  \\ 
		\bottomrule
	\end{tabular}
	\label{tab:params_linear}
\end{table}

\subsection{Measurement Signal-to-Noise Ratio Variation}\label{sec:ruido-AC}

%For the first simulation scenario, we consider SNR variation for both the process and observation models jointly. Chosen parameters are presented in Table~\ref{tab:params_linear_snr} and results for the performance metrics are shown in column (a) of Figure~\ref{fig:linear_sim}.


%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Linear system simulation parameters for SNR variation]{Linear system simulation parameters for SNR variation}
%	\begin{tabular}{c | c | c }
%		\toprule
%		SNR (dB)	& $\lambda$ (Hz) & $\alpha$\\
%		\midrule
%		$[60,\ 50,\ 40,\ 20,\ 10]$	& $500$ & $1$ \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_linear_snr}
%\end{table}

%Regular estimation time interval $T$ is maintained fixed at $T=0.002 \textrm{s}$  and $\alpha=1$, thus $\lambda=500 \textrm{Hz}$. For a 100-run simulation, the obtained results for accuracy and consistency are presented in Figure~\ref{fig:linearNoise} with the corresponding $95\%$ confidence intervals.


% \begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearNoise_x1_rmse.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearNoise_x4_rmse.eps}}  \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearNoise_NEES.eps}}
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearNoise_NIS.eps}}
%	\caption[Linear system estimation performance, as a function of input and observation SNR]{Linear system estimation performance indices with $95\%$ confidence intervals, as a function of input and observation SNR, for algorithms with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Accuracy values for states $x_1$ and $x_2$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%	\label{fig:linearNoise}
%\end{figure}

Results from the first column of Figure~\ref{fig:linear_sim} suggest that for higher SNR levels, that is when less noise is present in data, taking into account time-stamp information plays a more effective role. In terms of accuracy, the algorithm with time-stamp performed better at all levels, except for the high-pass system state $x_4$, at SNR of $10$ dB, for which confidence levels overlap a little. Nevertheless, it is interesting to note the trend of accuracy performance approximate between both algorithms, as noise levels increase. Consistency tests for the algorithm with time-stamp remains almost constant for all SNR values, whereas for the algorithm without time-stamp they start at higher levels, but decrease to values that do not differ statistically from both methods. This behavior for the algorithm without time-stamp can be explained due to the fact that for lower noise levels, the covariance of observations are overestimated. It does not take into account the additional noise tuned by the incorrect time instant when data is assimilated. For higher SNR, the additional noise become less significant, so results are not so overestimated.

%\subsubsection{Changing only measurement noise}
%
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=1\textwidth]{Imagens/noise_results_all.eps}
%	\caption[Performance, as a function of observation SNR]{Performance, as a function of observation SNR.}
%	\label{fig:ulinearSamp2}
%\end{figure} 
%
%
%
%%	
%%\begin{figure}[H]
%%	\centering
%%	\includegraphics[width=0.8\textwidth]{Imagens/linearNoise.eps}
%%	\caption[entrada]{Root mean square error variation, as a function of measurement noise for both KF algorithms, considering and not considering time-stamp}
%%	\label{fig:linearNoise}
%%\end{figure} 


\subsection{Average Sampling Rate Variation}\label{sec:lambda-AC}

%In the second simulation scenario for the linear system, we consider a variation of average sampling rate of observation $\lambda$, keeping other parameters fixed. Table~\ref{tab:params_linear_lambda} shows the used parameters and column (b) of Figure~\ref{fig:linear_sim}, the obtained results.

%
%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Linear system simulation parameters for $\lambda$ variation]{Linear system simulation parameters for $\lambda$ variation}
%	\begin{tabular}{c | c | c }
%		\toprule
%		SNR (dB)	& $\lambda$ (Hz) & $\alpha$ \\
%		\midrule
%		$30$		&  $[1000,\ 500,\ 200,\ 100]$ & $1$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_linear_lambda}
%\end{table}

%
%$\lambda \ =\ 1000,\ 500,\ 20,\ \textrm{and } 10 \textrm{ Hz}$. Relation between $\lambda^{-1}$ and $T$ is kept constant $\alpha=1$. SNR levels for process and observation models are chosen to be $SNR_{\textrm{obs}} = SNR_{\textrm{pro}} = 30 \ \textrm{dB}$. Simulation was carried out 100 times and performance indices for accuracy and consistency are shown in Figure~\ref{fig:linearSamp} with corresponding $95\%$ confidence intervals. 
%
% \begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearSamp_x1_rmse.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearSamp_x4_rmse.eps}}  \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearSamp_NEES.eps}}
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearSamp_NIS.eps}}
%	\caption[Linear system estimation performance, as a function of input and observation SNR]{Linear system estimation performance indices with $95\%$ confidence intervals, as a function of average time interval $\lambda^{-1}$, for algorithms with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Accuracy values for states $x_1$ and $x_2$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%	\label{fig:linearSamp}
%\end{figure}

Variation of performance indices for $\lambda$ variation are shown in the second column of Figure~\ref{fig:linear_sim}. In this case, the higher the $\lambda$, the higher is the difference in algorithm performance, in favor of the one that considers time-stamp information. Smaller observation sampling rates $\lambda$ used for simulation reduced the accuracy performance difference of both algorithms. It also decreased the RMSE variability of the algorithm without time-stamp. It suggests that, the more sparse are the time intervals of observations, the bigger is the importance of correctly incorporating time instant information in the estimation process. That can be explained by the fact that in such cases, the approximation errors of $t_k$ are higher and so is the additional noise introduced by data assimilation performed at incorrect time instants. Consistency values, however, were not impacted by the different parameter combination of this scenario. Considering time-stamp always produced consistent estimates, whereas neglecting time-stamp information resulted in inconsistent estimates in all cases.


\subsection{Regular and Average Irregular Time Interval Relation Variation}\label{sec:alpha-AC}

%The last linear system case study results, that is variation of $\alpha$, are shown in the third column of Figure~\ref{fig:linear_sim}. Used parameters are shown in Table~\ref{tab:params_linear_alpha} and results are presented in column (c) of Figure~\ref{fig:linear_sim}.


%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Linear system simulation parameters for $\alpha$ variation]{Linear system simulation parameters for $\alpha$ variation}
%	\begin{tabular}{c | c | c }
%		\toprule
%		SNR (dB)	& $\lambda$ (Hz) & $\alpha$ \\
%		\midrule
%		$30$		&  $500$ & $[5,\ 3,\ 2,\ 1]$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_linear_alpha}
%\end{table}
%

% \begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearAlpha_x1_rmse.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearAlpha_x4_rmse.eps}}  \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearAlpha_NEES.eps}}
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/linearAlpha_NIS.eps}}
%	\caption[Linear system estimation performance, as a function of input and observation SNR]{Linear system estimation performance indices with $95\%$ confidence intervals, as a function of $\alpha$, for algorithms with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Accuracy values for states $x_1$ and $x_2$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%	\label{fig:linearAlpha}
%\end{figure}

The last linear system case study results, that is variation of $\alpha$, are shown in the third column of Figure~\ref{fig:linear_sim}. For different values of $\alpha$, the performance of the algorithm with time-stamp remained almost constant for both for accuracy and consistency indices, suggesting that it does not depend on the relation between estimation and observation rates. On the other hand, results for the algorithm that does not consider time-stamp are better when regular estimation sampling rate is higher. That is, when input information is available at faster rates in comparison to the average sampling rate of observations, knowing the exact time instant $t_k$ becomes less important. It can be explained due to the reduction in time instant approximation errors, given by $\tilde{y}_i \approx y(t_k)$.


 \begin{figure}[!htb]
	\centering
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearNoise_x1_rmse.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearSamp_x1_rmse.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearAlpha_x1_rmse.eps}} \\
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearNoise_x4_rmse.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearSamp_x4_rmse.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearAlpha_x4_rmse.eps}} \\
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearNoise_NEES.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearSamp_NEES.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearAlpha_NEES.eps}} \\
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearNoise_NIS.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearSamp_NIS.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/linearAlpha_NIS.eps}} \\
	\caption[Linear system estimation performance comparison]{Linear system estimation performance indices with $95\%$ confidence intervals, as a function of SNR (a), $\lambda$ (b) and $\alpha$ (c), for algorithms with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Accuracy values for RMSE are shown in the first and second rows, for states $x_1$ and $x_4$, respectively. Consistency results are in third and fourth rows, for NEES and NIS tests, respectively}
	\label{fig:linear_sim}
\end{figure}


%
%\subsection{Average Time Delay}\label{sec:dt-AC}
%
%\todo[inline,caption={Falta variar o atraso nas medições}]{Ainda terá uma seção com a variação do time-delay e seu impacto no desempenho}


\section{Nonlinear System: Unicycle Position}

We now consider a nonlinear system given by a nonholomonic moving unicycle robot, whose position in the $xy$-plane must be estimated. In many real target tracking problems such as this, measurements are available by unsynchronized cameras through an internet network, for instance. In other applications multiple GPS sensors might be used in a centralized architecture without data alignment or association. These configurations are susceptible to sampling irregularities, which motivates our choice.

\subsection{System Description}

Consider a nonholomonic moving robot, with the cinematic process model given by

\setlength{\abovedisplayskip}{0.5pt}

\begin{equation}\label{eq:sistema}
\begin{split}
\dot{p}_\textrm{x} & = v\cos (\theta),\\
\dot{p}_\textrm{y} & = v\sin (\theta),\\
\dot{\theta}  & = u_1(t),\\
\dot{v} & = u_2(t),
\end{split}
\end{equation}

\noindent
where $p_\textrm{x}$ and $p_\textrm{y}$ are the position coordinates, $\theta$ the angular orientation, $v$ the linear velocity and inputs $u_1$ and $u_2$ are the angular velocity $\omega$ and the linear acceleration $a$, respectively. Figure~\ref{fig:robot} shows a schematic of the robot and its states,

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.4\textwidth]{Imagens/Nonholomonic-robot.pdf}
	\caption[Nonholomonic robot system representation]{Nonholomonic robot system representation. The system states $p_\textrm{x}$, $p_\textrm{y}$, $v$ and $\theta$ are highlighted.}
	\label{fig:robot}
\end{figure} 

The system described by (~\ref{eq:sistema}) is discretized by a fourth order Runge-Kutta method as described in Section~\ref{sec:discretization} and the discrete state vector $x_i$ is given by $x_i \overset{\Delta}{=} [p_{\textrm{x},i}\ \  p_{\textrm{y},i}\ \  \theta_i\ \  v_i]^T$, where subscript $i$ indicate discrete instants $iT$.

The observation model $y(t_k) \in \mathbb{R}^2$

\begin{equation}
y(t_k) = 
\begin{bmatrix}
p_\textrm{x}(t_k) \\
p_\textrm{y}(t_k)
\end{bmatrix}+v(t_k), \\
\end{equation}

\noindent
is given by the position coordinates, and $\rho(v(t_k)) = \mathcal{N} (0,R_{t_k})$ is the observation noise PDF, with zero mean and covariance $R_{t_k}$. Discrete time instants with $t_k$ are determined by random time intervals $h_k$, that is $t_{k+1}=t_k+h_k$. When time-stamp information about $t_k$ is not available, the observation vector is approximated by $\tilde{y}_i \approx y(t_k)$, where $i$ is the index of the next time instant, multiple of $T$.

Input vector $u_i = [\omega_i\ \ a_i]^T$ is measured by a girometer and accelerometer, respectively. We assume that 

\begin{equation}\label{eq:entrada}
u_i = \tilde{u}_i - w_i,
\end{equation}

\noindent
where $\tilde{u}$ represent the sensors' measured values and $\rho(w_i) = \mathcal{N} (0, Q_i)$ is the corresponding noise PDF, with zero mean and covariance $Q_i$. 

We simulate 60 seconds of robot movement, considering a step size of $\delta t_{\textrm{sim}} = 10^{-4}$. Input signals are generated arbitrarily according to Figure~\ref{fig:entrada}. 

Accuracy metrics for the unicycle position system is a modification of the RMSE defined in (\ref{eq:rmse}), to reflect error in $xy$-plane position, given by:

\begin{equation}\label{eq:pos_rmse}
RMSE_{\textrm{position}} = \frac{ \sum_{i=1}^N \sqrt{(\hat{p}_{\textrm{x},i}-p_{\textrm{x},i})^2+(\hat{p}_{\textrm{y},i}-p_{\textrm{y},i})^2}}{N},
\end{equation}

\noindent
where $\hat{p}_{\textrm{x},i}$ and $\hat{p}_{\textrm{y},i}$ are position estimates at regularly spaced time intervals $T$, $p_{\textrm{x},i}$ and $p_{\textrm{y},i}$ are true position coordinates of the unicycle, at the same time instants and $N$ is the total amount of estimates.


%sampling time intervals $h_k$ are simulated by the exponential probability distribution function from Matlab\texttrademark \ and approximated to the nearest discrete time instant, from the 600,000 available samples. 


\subsection{Unicycle Position System}

Figure~\ref{fig:exukf} shows the robot trajectory on the $xy$-plane for the given input signals, leaving from point $(0,0)$, as well as a realization of noisy and aperiodic measurements as red dots, with signal-to-noise ratio of $\textrm{SNR\textsubscript{y}} = 30$ dB and $\lambda=3.33$ Hz. Dashed blue line represents UKF estimation, considering time-stamp, $\alpha=5$ and $\textrm{SNR\textsubscript{u}} = 10 \textrm{ dB}$. 

\begin{figure}[!htb]
	\centering
	\subfigure{\includegraphics[width=0.8\textwidth]{Imagens/entradas1.eps}} \\
	\subfigure{\includegraphics[width=0.8\textwidth]{Imagens/entradas2.eps}}  
	\caption[Simulation input signals]{Simulation input signals. (a) shows temporal sequence of angular velocity $\omega$ and (b) shows linear acceleration $a$.}
	\label{fig:entrada}
\end{figure}



\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.7\textwidth]{Imagens/exemplo_03_30db_desloc.eps}
	\caption[True position, noisy measurements and UKF estimates]{True position (\textcolor{black}{---}), noisy measurements (\textcolor{red}{$\cdot$}) and UKF estimates (\textcolor{blue}{- -}) considering time-stamp, for a measurement noise of SNR\textsubscript{y} $= 30$ dB, $\lambda=0.3$ s and $\alpha=5$.}
	\label{fig:exukf}
\end{figure} 

Figure~\ref{fig:realizacaoJ} shows a timespan from $0$ to $1.5$ seconds of a realization of position RMSE, considering $\lambda=0.5$, $\alpha=2$, $\textrm{SNR\textsubscript{y}} = 40 \textrm{ dB}$ and $\textrm{SNR\textsubscript{u}} = 20 \textrm{ dB}$, for the UKF considering and not considering time-stamp. Black dots represent the regular time instants $kT$ whereas the asterisks on $x$-axis and dashed vertical lines match the exact measurement instants $t_k$. The first two measurements, before 0.25 seconds, are very close to the first regular time instant $1T = 0.25 \textrm{ s}$ and thus cause no significant difference on performance. It is expected, since the approximation error due to $\tilde{y}_i \approx y(t_k)$ is irrelevant. Next measurement $t_3$, taking place around $0.8$ seconds, when assimilated correctly reduces the estimate error at the correct instant. When assimilated at the next estimation time instant, the position error is not decreased appropriately. At $t_4$, around $1.1$ seconds, we can see another effect of assimilating the measurement at the correct time, with the red line decreasing slightly. 

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.7\textwidth]{Imagens/RobotJEvolution.eps}
	\caption[Performance index temporal cut for one realization]{Temporal cut from 0 to 1.5 seconds, for a realization of $J$ of both estimators, with and without time-stamp. Asterisks on $x$ axis and vertical dashed lines match the measurement sampling instants $t_k$. Black dots represent the regular estimation instants, same as input regular sampling instants.}
	\label{fig:realizacaoJ}
\end{figure} 

In the next sections we perform Monte Carlo simulations, with 1000 runs per combination of parameters, for the scenarios from Section~\ref{sec:scenarios}. Simulation parameters used for the nonlinear system are shown in Table~\ref{tab:params_robot}. For all cases, input SNR is constant at $20$ dB. All results are comprised in Figure~\ref{fig:robot_sim}, with the evolution of mean values in solid lines and the corresponding $95\%$ confidence interval in dashed lines. First row of graphs shows accuracy results for position RMSE, as described in (\ref{eq:pos_rmse}). Second and third rows present the consistency results for NEES and NIS tests, respectively, as described in Section~\ref{sec:metrics}. The blue lines are for the algorithm that considers time-stamp and red lines are for the one without time-stamp.

\begin{table}[!ht]
	\centering
	\setlength{\tabcolsep}{12pt}
	\caption[Nonlinear system simulation parameters for SNR variation]{Unicycle position estimation simulation parameters for observation SNR variation}
	\renewcommand{\arraystretch}{1.5}

	\begin{tabular}{c | c | c | c }
		\toprule
		Scenario 		& SNR observations (dB)	& $\lambda$ (Hz) & $\alpha$ \\
		\midrule
		SNR variation 	& $[100, \ 80,\ 60,\ 40,\ 20,\ 10]$ &  $10$ & $2$  \\
		$\lambda$ variation			$40$ & 	 $[10, \ 5,\ 0.33,\ 2.5,\ 2,\ 1.67]$ & $2$  \\
		$\alpha$ variation	&$40$ 				&  $10$ & $[10, \ 5,\ 2,\ 1]$  \\
		\bottomrule
	\end{tabular}
	\label{tab:params_robot}
\end{table}


%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.8\textwidth]{Imagens/J_umarealizacao-timedelay.eps}
%%%	\caption[entrada]{Recorte temporal de 1 a 1.3 segundo, do índice J de uma realização dos dois estimadores, com e sem carimbo de tempo. Os asteriscos no eixo $x$ representam os instantes de amostragem das observações $t_k$. Os pontos pretos apresentados nas linhas representam os instantes de tempo regulares de amostragem da entrada}
%	\label{fig:realizacaoJ2}
%\end{figure} 



%\setlength{\abovedisplayskip}{0.5pt}
%
%\begin{equation}\label{eq:sistema}
%\begin{split}
%\dot{\delta_e} & = -\tau^{-1},\\
%\dot{W} & = Z_{de}\delta_e + Z_wW + S_0q,\\
%\dot{q}  & = S_1 \delta_e + S_2 W + S_3q,\\
%\end{split}
%\end{equation}
%\noindent

\subsection{Measurement Signal-to-Noise Ratio Variation}\label{sec:ruido-robo}

%In this subsection we compare the estimation performance impact of considering time-stamp in the algorithm, by varying the measurement noise level. The signal-to-noise ratio for the input sensors, the measurement average time interval and $\alpha$ are held constant. Table~\ref{tab:params_robot_snr} shows the parameters used in simulation.

%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Nonlinear system simulation parameters for SNR variation]{Unicycle position estimation simulation parameters for observation SNR variation}
%	\begin{tabular}{c | c | c | c }
%		\toprule
%		SNR observations (dB)	& SNR input (dB) & $\lambda$ (Hz) & $\alpha$ \\
%		\midrule
%		$[100, \ 80,\ 60,\ 40,\ 20,\ 10]$ & $20$ & $10$ & $2$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_robot_snr}
%\end{table}



% \begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/noise.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/noise.eps}}  \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/noise.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/noise.eps}}     
%
%	\caption[Robot tracking performance, as a function of measurement noise]{Robot tracking performance indices with $95\%$ confidence intervals, as a function of measurement noise, for both UKF algorithms considering (\textcolor{red}{---}) and not considering (\textcolor{blue}{---}) time-stamp. Accuracy values for states $P_{\textrm{x}}$ and  $P_{\textrm{y}}$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%	\label{fig:robot_noise}
%\end{figure}

Results from the first column of Figure~\ref{fig:robot_sim} show the variation in performance indices for the different measurement SNR levels simulated. There is a significant difference in the size of the $95\%$ confidence interval for the results, indicating that the algorithm without time-stamp performs with a much higher variability in accuracy and consistency metrics. Such uncertainty in the performance metrics is by itself a drawback of neglecting time-stamp information. Additionally, results indicate that for lower noise levels, that is higher SNR, considering time-stamp results in significantly better performance, in both aspects of accuracy and consistency. When noise achieves higher levels, around $10$ dB, performance of both algorithms cannot be statistically distinguished. Similar to what happened in the linear system, it can be explained by the relation between signal noise and the additional noise tuned by the incorrect time instants. 

\subsection{Average Sampling Rate Variation}\label{sec:lambda-robot}

%We now consider the variation of the average sampling rate that observations are taken, maintaining the other parameters constant, according to Table~\ref{tab:params_robot_lambda}. Results for accuracy and consistency are shown in column (b) of .
%%
%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Nonlinear system simulation parameters for $\lambda$ variation]{Unicycle position estimation simulation parameters for observation $\lambda$ variation}
%	\begin{tabular}{c | c | c | c }
%		\toprule
%		SNR observations (dB)	& SNR input (dB) & $\lambda$ (Hz) & $\alpha$ \\
%		\midrule
%		$40$ 				& $20$ 		& $[10, \ 5,\ 0.33,\ 2.5,\ 2,\ 1.67]$ & $2$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_robot_lambda}
%\end{table}


%\begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/samp.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/samp.eps}}  \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/samp.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/samp.eps}}   
%	\caption[Robot tracking performance, as a function of measurement noise]{Robot tracking performance indices with $95\%$ confidence intervals, as a function of $\lambda$, for both UKF algorithms considering (\textcolor{red}{---}) and not considering (\textcolor{blue}{---}) time-stamp. Accuracy values for states $P_{\textrm{x}}$ and  $P_{\textrm{y}}$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%
%	\label{fig:samp}
%\end{figure}

As for different $\lambda$ values, variation of indices is presented in the second column of Figure~\ref{fig:robot_sim}. Results show that performance degradation is more significant for more sparse time intervals, providing that dynamics and other parameters are kept constant. For higher  $\lambda$ rates, there are no statistical differences in performance. As average time interval grows, degradation increases and it starts to be apparent, reaching mean differences of $3.1$ cm for a $\lambda = 1.667$ Hz. One possible explanation derives from the fact if average sampling rate is considerably higher than system dynamics speed, then time instant $t_k$ approximations errors are reduced. In such cases, sensor noise might end up being much more relevant than the error tunned by assimilating data at incorrect instants.

\subsection{Regular and Average Irregular Time Interval Relation Variation}\label{sec:alpha-robot}

%We also analyze the performance impact of varying the parameter $\alpha$, which is the relation between regular input time interval $T$ and average measurements time interval $\lambda^{-1}$. Table~\ref{tab:params_robot_alpha} presets the used values for simulation and results are presented in column (c) of Table~\ref{tab:params_robot_alpha}. Results for accuracy and consistency are shown in column (b) of }.

%
%\begin{table}[!ht]
%	\centering
%	\setlength{\tabcolsep}{12pt}
%	\caption[Nonlinear system simulation parameters for $\alpha$ variation]{Unicycle position estimation simulation parameters for observation $\alpha$ variation}
%	\begin{tabular}{c | c | c | c }
%		\toprule
%		SNR observations (dB)	& SNR input (dB) & $\lambda$ (Hz) & $\alpha$ \\
%		\midrule
%		$40$ 				& $20$ 		& $10$ & $[10, \ 5,\ 2,\ 1]$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:params_robot_alpha}
%\end{table}


%\begin{figure}[!htb]
%	\centering
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/dtudty.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/dtudty.eps}} \\
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/dtudty.eps}} 
%	\subfigure[]{\includegraphics[width=0.49\textwidth]{Imagens/dtudty.eps}}   
%
%	\caption[Robot tracking performance, as a function of measurement noise]{Robot tracking performance indices with $95\%$ confidence intervals, as a function of $\alpha$, for both UKF algorithms considering (\textcolor{red}{---}) and not considering (\textcolor{blue}{---}) time-stamp. Accuracy values for states $P_{\textrm{x}}$ and  $P_{\textrm{y}}$ are shown in (a) and (b), respectively. Consistency results are in (c) and (d) for NEES and NIS tests, respectively.}
%
%	\label{fig:dtudty}
%\end{figure}
Finally, the last scenario results are shown in the third column of Figure~\ref{fig:robot_sim}. The same way as it happened for the linear system, indices variation suggest that when exact time instants $t_k$ are available, variations of $\alpha$ do not impact estimation performance. On the other hand, when time-stamp is not considered in the estimation process, the relation between time intervals of regular estimation and irregular measurement plays an important role in estimates accuracy. The higher is the regular estimation rate in comparison to measurement rate, smaller is the degradation. In fact, for $\alpha$ values of 10 and 5, performance are statistically indistinguishable. When the rates are the same, the position estimate error doubled for the algorithm that does not consider time stamp. Such phenomenon can be explained by the fact that higher $\alpha$ values lead to smaller time steps used in the process model discretization in comparison to the measurement time intervals. Thus, approximation error originated from $\tilde{y}(i) \approx y(t_k)$ is reduced.


 \begin{figure}[!htb]
	\centering
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotNoise_rmse.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotSamp_rmse.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotUsamp_rmse.eps}} \\
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotNoise_NEES.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotSamp_NEES.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotUsamp_NEES.eps}} \\
	\subfigure[SNR variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotNoise_NIS.eps}} 
	\subfigure[$\lambda$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotSamp_NIS.eps}}  
	\subfigure[$\alpha$ variation]{\includegraphics[width=0.32\textwidth]{Imagens/robotUsamp_NIS.eps}} \\
	\caption[Nonlinear system estimation performance comparison]{Nonlinear system estimation performance indices with $95\%$ confidence intervals, as a function of SNR (a), $\lambda$ (b) and $\alpha$ (c), for algorithms with (\textcolor{red}{---}) and without (\textcolor{blue}{---}) time-stamp. Accuracy values for RMSE are shown in the first row. Consistency results are in second and third rows, for NEES and NIS tests, respectively.}
	\label{fig:robot_sim}
\end{figure}


\section{Simulated Results Discussion}

Two different system are simulated to address the effects of neglecting time-stamp in state estimation performance: a linear fourth order system, with two underdamped modes; and a nonlinear unicycle position system. We design three scenarios in which only one parameter of interest is varied, while the others are kept constant. That way, we can infer the contribution to performance variation to each of the parameter: SNR; $\lambda$; and $\alpha$.

For both systems, performance metrics obtained by neglecting time-stamp had a higher variability in most of the simulations, indicating that estimate accuracy and consistency are less reliable if incorrect time instants are used in estimation. For the nonlinear system, such variability made results comparison more difficult, since statistically significant differences are not apparent.

The average performance metrics for the algorithm considering time-stamp were always higher or equal to the metrics from the algorithm without time-stamp, as expected. Accuracy performance for SNR variation suggested that for lower noise levels, the difference of considering or neglecting time-stamp is much more significant. As noise levels increase, performance for both algorithms tend to approximate. In the nonlinear simulation, RMSE for the highest noise level simulated were statistically indistinguishable. When the average sampling rate of observations $\lambda$ and the relation between them and the regular sampling rate $\alpha$ were altered, the algorithm that considers time-stamp maintained its performance metrics almost constant, specially for consistency tests, as it was expected. Results for the algorithm neglecting time-stamp did not provide many insights, since average values varied little, specially considering their confidence interval.
 




%\subsection{Average Time Delay}\label{sec:dt-robot}
%
%\todo[inline,caption={Falta variar o atraso nas medições}]{Ainda terá uma seção com a variação do time-delay e seu impacto no desempenho}


\clearpage
